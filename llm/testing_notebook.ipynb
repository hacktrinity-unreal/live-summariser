{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from typing import Generator\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "\n",
    "os.system(\"sh ../.env\")\n",
    "YOUR_API_KEY = os.environ[\"YOUR_API_KEY\"]\n",
    "print(YOUR_API_KEY)\n",
    "MODEL_NAME_HERE = \"llama-3.1-sonar-large-128k-online\"\n",
    "\n",
    "with open(\"comments.txt\",\"w\") as f:\n",
    "    pass\n",
    "with open(\"summary.txt\",\"w\") as f:\n",
    "    pass\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def convert_mp4_to_wav(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Convert an MP4 video file to a WAV audio file using FFmpeg.\n",
    "    \n",
    "    :param input_file: The input .mp4 file path.\n",
    "    :param output_file: The output .wav file path.\n",
    "    \"\"\"\n",
    "    # Use FFmpeg command to convert MP4 to WAV\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\", input_file,      # Input file\n",
    "        \"-vn\",                  # No video\n",
    "        \"-acodec\", \"pcm_s16le\",  # Audio codec\n",
    "        \"-ar\", \"44100\",        # Sample rate\n",
    "        \"-ac\", \"2\",            # Number of audio channels\n",
    "        output_file            # Output file path\n",
    "    ]\n",
    "    \n",
    "    # Run the command\n",
    "    subprocess.run(command, check=True)\n",
    "    print(f\"Converted {input_file} to {output_file}\")\n",
    "\n",
    "# Example usage:\n",
    "input_mp4_file = \"/home/fedora/data/oj1.mp4\"\n",
    "output_wav_file = \"output.wav\"\n",
    "\n",
    "if not \"output.wav\" in os.listdir():convert_mp4_to_wav(input_mp4_file, output_wav_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "CHUNK_SIZE = 60000  # milliseconds\n",
    "\n",
    "\n",
    "\n",
    "def speech_to_text(audio_path: str) -> Generator[str, None, None]:\n",
    "    audio = AudioSegment.from_wav(audio_path)\n",
    "    num_chunks = len(audio) // CHUNK_SIZE + (1 if len(audio) % CHUNK_SIZE > 0 else 0)\n",
    "    try:\n",
    "        os.mkdir(\n",
    "        \"temp\"\n",
    "        )\n",
    "    except:\n",
    "        os.system(\"temp/*\")\n",
    "\n",
    "    td= \"temp\"\n",
    "    for i in range(num_chunks):\n",
    "        start_time = i * CHUNK_SIZE\n",
    "        end_time = start_time + CHUNK_SIZE\n",
    "        chunk = audio[start_time:end_time]\n",
    "        chunk_filename = f\"{td}/chunk_{i}.wav\"\n",
    "        chunk.export(chunk_filename, format=\"wav\")\n",
    "\n",
    "        yield _recognise_text(chunk_filename)\n",
    "\n",
    "\n",
    "def _recognise_text(audio_path: str) -> str:\n",
    "    recogniser = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        data = recogniser.record(source)\n",
    "\n",
    "    text = recogniser.recognize_google(data)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = speech_to_text(\"output.wav\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object speech_to_text at 0x7f9528d2ef00>\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def chunk_trancript(text):\n",
    "# Load GPT-4 tokenizer\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "    max_tokens = 8000\n",
    "    tokens = encoding.encode(text)\n",
    "    chunks = [tokens[i:i + max_tokens] for i in range(0, len(tokens), max_tokens)]\n",
    "\n",
    "    \n",
    "    text_chunks = [encoding.decode(chunk) for chunk in chunks]\n",
    "    return text_chunks\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_message(chunks):\n",
    "    prev_chunk = None\n",
    "    prev_summarization = None\n",
    "    messages = []\n",
    "    for i in range(len(chunks)):\n",
    "        current_chunk = chunks[i]\n",
    "        current_message = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are a lawyer who summarises the transcript of legal cases. Be concise, accurate and understandable.\"\n",
    "                ),\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    f\"Summarize the current body of text, which is a chunk of a larger document '{current_chunk}'. Your summarization should contain all the important details in a readable form. Be concise. Here is the previus\"\n",
    "                ),\n",
    "            },\n",
    "        ]\n",
    "        messages.append(current_message)\n",
    "    return messages\n",
    "def gen_single_message(chunk,text_response):\n",
    "    postfix = f\"Here is the summary that was generated from the previous chunk '{text_response}'\" if  text_response  else \"\"\n",
    "    current_message = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a lawyer who summarises the transcript of legal cases. Be concise, accurate and understandable. Do not include an introduction or a conclusion. Speak in a neutral tone and do not give advice. Only discuss what is in the source material. Use a tone that would fit in a news article.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"Summarize the current body of text, which is a chunk of a larger document '{chunk}'. Your summarization should contain all the important details in a readable form. Be concise.\"+postfix\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "    return current_message\n",
    "\n",
    "def gen_lawyer_message(summaries):\n",
    "    current_message = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a lawyer who analyzes snippets court cases based on their transcripts/summaries. Provide insightful and interesting commentary on the proceedings of the cases. Keep your comments short and to the point, do not give an introduction or conclusion.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f'Analyze the following proceedings and give unique and interesting opinions on it. Clarify any points that may not be accessible to a general audience.\"{' '.join(summaries)}\"'\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "    return current_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: line 1: temp/chunk_0.wav: Permission denied\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text_response\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m     text_chunks \u001b[38;5;241m=\u001b[39m chunk_trancript(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     23\u001b[0m     client \u001b[38;5;241m=\u001b[39m OpenAI(api_key\u001b[38;5;241m=\u001b[39mYOUR_API_KEY, base_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.perplexity.ai\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m     outputs,summaries \u001b[38;5;241m=\u001b[39m [],[]\n",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m, in \u001b[0;36mspeech_to_text\u001b[0;34m(audio_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m chunk_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtd\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/chunk_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m chunk\u001b[38;5;241m.\u001b[39mexport(chunk_filename, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_recognise_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_filename\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 31\u001b[0m, in \u001b[0;36m_recognise_text\u001b[0;34m(audio_path)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sr\u001b[38;5;241m.\u001b[39mAudioFile(audio_path) \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[1;32m     29\u001b[0m     data \u001b[38;5;241m=\u001b[39m recogniser\u001b[38;5;241m.\u001b[39mrecord(source)\n\u001b[0;32m---> 31\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mrecogniser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize_google\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/speech_recognition/recognizers/google.py:256\u001b[0m, in \u001b[0;36mrecognize_legacy\u001b[0;34m(recognizer, audio_data, key, language, pfilter, show_all, with_confidence, endpoint)\u001b[0m\n\u001b[1;32m    251\u001b[0m request_builder \u001b[38;5;241m=\u001b[39m create_request_builder(\n\u001b[1;32m    252\u001b[0m     endpoint\u001b[38;5;241m=\u001b[39mendpoint, key\u001b[38;5;241m=\u001b[39mkey, language\u001b[38;5;241m=\u001b[39mlanguage, filter_level\u001b[38;5;241m=\u001b[39mpfilter\n\u001b[1;32m    253\u001b[0m )\n\u001b[1;32m    254\u001b[0m request \u001b[38;5;241m=\u001b[39m request_builder\u001b[38;5;241m.\u001b[39mbuild(audio_data)\n\u001b[0;32m--> 256\u001b[0m response_text \u001b[38;5;241m=\u001b[39m \u001b[43mobtain_transcription\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperation_timeout\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m output_parser \u001b[38;5;241m=\u001b[39m OutputParser(\n\u001b[1;32m    261\u001b[0m     show_all\u001b[38;5;241m=\u001b[39mshow_all, with_confidence\u001b[38;5;241m=\u001b[39mwith_confidence\n\u001b[1;32m    262\u001b[0m )\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_parser\u001b[38;5;241m.\u001b[39mparse(response_text)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/speech_recognition/recognizers/google.py:222\u001b[0m, in \u001b[0;36mobtain_transcription\u001b[0;34m(request, timeout)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m URLError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestError(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecognition connection failed: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e\u001b[38;5;241m.\u001b[39mreason)\n\u001b[1;32m    221\u001b[0m     )\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib64/python3.12/http/client.py:473\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked:\n\u001b[0;32m--> 473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib64/python3.12/http/client.py:595\u001b[0m, in \u001b[0;36mHTTPResponse._read_chunked\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    593\u001b[0m value \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 595\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m (chunk_left \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_chunk_left\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    596\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m chunk_left:\n\u001b[1;32m    597\u001b[0m             value\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_safe_read(amt))\n",
      "File \u001b[0;32m/usr/lib64/python3.12/http/client.py:579\u001b[0m, in \u001b[0;36mHTTPResponse._get_chunk_left\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_safe_read(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# toss the CRLF at the end of the chunk\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 579\u001b[0m     chunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_next_chunk_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib64/python3.12/http/client.py:539\u001b[0m, in \u001b[0;36mHTTPResponse._read_next_chunk_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_next_chunk_size\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;66;03m# Read the next chunk size from the file\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    541\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib64/python3.12/socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def summarize_chunk(chunk,text_response):\n",
    "    message = gen_single_message(chunk,text_response)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME_HERE,\n",
    "        messages=message,\n",
    "    )\n",
    "    text_response = response.choices[0].message.content.strip()\n",
    "    return text_response\n",
    "def comment_on_summaries(outputs):\n",
    "    message = gen_lawyer_message(outputs)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME_HERE,\n",
    "        messages=message,\n",
    "    )\n",
    "    text_response = response.choices[0].message.content.strip()\n",
    "    return text_response\n",
    "\n",
    "while True:\n",
    "    text_chunks = chunk_trancript(next(text))\n",
    "\n",
    "    client = OpenAI(api_key=YOUR_API_KEY, base_url=\"https://api.perplexity.ai\")\n",
    "\n",
    "    outputs,summaries = [],[]\n",
    "    text_response = None\n",
    "    # chat completion without streaming\n",
    "    for chunk in text_chunks:\n",
    "        text_response = summarize_chunk(chunk,text_response)\n",
    "        with open(\"summary.txt\",\"a\") as f:\n",
    "            f.write(text_response)\n",
    "        outputs.append(text_response)\n",
    "        lawyer_comment = comment_on_summaries(outputs)\n",
    "        with open(\"comments.txt\",\"a\") as f:\n",
    "            f.write(lawyer_comment)\n",
    "\n",
    "        summaries.append(lawyer_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
